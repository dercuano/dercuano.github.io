<!DOCTYPE html>
<html><title>Incremental MapReduce for Abelian-group reduction functions ⁑ Dercuano</title><meta charset="utf-8"></meta><link href="../liabilities/style.css" rel="stylesheet"></link><meta content="width=device-width, initial-scale=1.0" name="viewport"></meta><h1>Incremental MapReduce for Abelian-group reduction functions</h1><div class="metadata">Kragen Javier Sitaker, 2015-09-03
(4 minutes)</div><p><a href="https://www.usenix.org/legacy/events/osdi04/tech/dean.html">MapReduce</a>
is a batch-processing framework.  Manuel Simoni <a href="http://permalink.gmane.org/gmane.comp.db.couchdb.devel/402">wrote about
incremental MapReduce in
2008</a> and
is working on it still.  He explains that in <a href="http://damienkatz.net/2008/02/incremental_map.html">Damien Katz’s proposed
solution</a>, “you
have to store intermediate results and do recomputation when the
inputs change,” but you can avoid this if “map() stays the same, but
reduce() is extended so that it takes a diff of the map outputs from
before and after a document update.”  Simoni’s design has an
additional benefit over Katz’s: Katz’s will nearly always involve
re-executing the entire reduce() stage.  Simoni’s design does,
however, involve storing the final reduce() output.</p>
<p>This is a very interesting idea.  Simoni comments that it has a
drawback:</p>
<blockquote>
<p>[R]educe functions get more complex in this scheme, but the Google
papers on MapReduce and Sawzall suggest that map functions are much
more often user defined than reduce functions.</p>
</blockquote>
<p>There’s actually a whole algebraic landscape associated with this
statement.</p>
<p>To <a href="https://www.mail-archive.com/kragen-tol@canonical.org/msg00298.html">summarize algebra in a few
lines</a>,
a magma that's associative is a semigroup, a semigroup that’s
commutative and idempotent is a semilattice, a semigroup with identity
is a monoid, a monoid with inverses is a group, and a commutative
group is an Abelian group.</p>
<p>In many cases, you can construct your reduce-function by composing an
Abelian group operation with some other operation.  Undoing an Abelian
group operation is relatively trivial: because the operation is
associative (because semigroup) it doesn’t matter what order the
operations were done in, and because it’s commutative, it doesn’t even
matter where in the sequence the removed element was.  So you can just
apply the inverse of the removed element to the previous
reduce-function result.</p>
<p>As one broadly applicable example, if we extend bags over some set A,
A → ℕ, to allow negative multiplicities, A → ℤ, then any bag has its
antibag which is its inverse under extended bag sum ⨄.</p>
<p>So if you store the result of the Abelian group operation, you can
apply the diff to it, then redo the final operation.</p>
<p>For example, to maintain the set of unique words present in a set of
documents, you can maintain in storage an extended bag that counts the
number of times each word occurs, and then just discard the
multiplicities to produce the final result.</p>
<p>As another example, if you want to know the largest one-second price
jump from a large collection of stock-market data, you can divide your
input data into shingles that overlap by a second, use a map function
that outputs just the largest jump in each shingle, and then use a
max-by-jump-size as your reduce function.  Unfortunately, max, like
semilattice operations generally, does not admit element inverses.  A
general incremental solution for this at the point of reduce would
involve maintaining, at least, a max-heap of existing records, to
which you could add and remove records.  Max-heaps, then, are the
Abelian group needed here.  But this has the same space cost (modulo
overhead) of Katz’s solution of storing previous map results and
re-executing affected reductions.</p>
<p>If you cannot decompose your reduce-function into an Abelian group
operation, the problem is more complex; but in fact reduce-functions
in MapReduce are almost invariably intended to be commutative and
associative, because the order in which the different map-results are
presented to them is more or less arbitrary.</p>
<p>The max-heap example points up an inadequacy in the group-based, or
even magma-based, analysis of incrementally updatable
reduce-functions: it requires that the things coming from the
map-functions be of the same type as the internal state of the
reduce-function.  In Haskell, <code>foldl</code> has type
<code>(a → b → a) → a → [b] → a</code> — it takes an initial <code>a</code>, produces a
final <code>a</code>, and in the middle it folds a list of <code>b</code>s into it using an
<code>a → b → a</code> function.  For example, <code>a</code> could be a max-heap of
stock-market price moves, and <code>b</code> could be a single stock-market price
move.</p><script src="../liabilities/addtoc.js"></script><div><h2>Topics</h2><ul><li><a href="../topics/programming.html">Programming</a> (286 notes)
</li><li><a href="../topics/algorithms.html">Algorithms</a> (123 notes)
</li><li><a href="../topics/sa.html">Systems architecture</a> (48 notes)
</li><li><a href="../topics/incremental-computation.html">Incremental computation</a> (24 notes)
</li><li><a href="../topics/algebra.html">Algebra</a> (11 notes)
</li><li><a href="../topics/parallelism.html">Parallelism</a> (8 notes)
</li><li><a href="../topics/trading.html">Trading</a> (4 notes)
</li><li>Mapreduce</li><li>Haskell</li></ul></div></html>