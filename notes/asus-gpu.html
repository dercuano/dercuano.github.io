<!DOCTYPE html>
<html><title>Notes on the Intel N3700 i915 GPU in this ASUS E403S laptop ⁑ Dercuano</title><meta charset="utf-8"></meta><link href="../liabilities/style.css" rel="stylesheet"></link><meta content="width=device-width, initial-scale=1.0" name="viewport"></meta><h1>Notes on the Intel N3700 i915 GPU in this ASUS E403S laptop</h1><div class="metadata">Kragen Javier Sitaker, 2018-10-28 (updated 2019-05-05)
(3 minutes)</div><p>So the “i915” Intel graphics are actually part of the N3700 SoC
<a href="https://en.wikichip.org/wiki/intel/pentium_(2009)/n3700">https://en.wikichip.org/wiki/intel/pentium_(2009)/n3700</a>, launched in
2015, which is a 1.6GHz quad-core amd64 CPU with 16 Braswell “HD
graphics” execution units, running at 400MHz.</p>
<p><a href="https://ark.intel.com/products/87261/Intel-Pentium-Processor-N3700-2M-Cache-up-to-2-40-GHz-">https://ark.intel.com/products/87261/Intel-Pentium-Processor-N3700-2M-Cache-up-to-2-40-GHz-</a></p>
<p><a href="https://en.wikipedia.org/wiki/List_of_Intel_graphics_processing_units#Eighth_generation">https://en.wikipedia.org/wiki/List_of_Intel_graphics_processing_units#Eighth_generation</a>
says this is of Intel’s “eighth generation”, and its core config is
“128:16:2” with 25.6 GB/s memory bandwidth, which means 128 FP32 ALUs,
16 EUs (“execution units”, each containing 2 SIMD-4 FPUs), and 2
subslices, each containing 8 EUs and a 4 texels-per-clock sampler.  It
also says that each EU is capable of 8 multiply-accumulates per clock
cycle (one per ALU, I guess) in single-precision floating-point, but
16-bit floating-point is capable of “2× floating-point performance”.
Also they can do integer operations at the 32-bit floating-point
speed, or 64-bit floating-point at ¼ the 32-bit speed.</p>
<p>Doing the math, that suggests that it can do 400 * 128 million
single-precision multiply-accumulates per second, or 51.2 billion.
Intel likes to double-count these multiply-accumulates, as if the
addition and the multiplication were two separate operations, which
dishonestly inflates their published flops counts by a factor of 2.</p>
<p>By contrast, <a href="https://en.wikipedia.org/wiki/Nvidia_Tesla">https://en.wikipedia.org/wiki/Nvidia_Tesla</a> says the
NVIDIA Tesla V100 GPU Accelerator, released in 2017, reaches 14900
single-precision Gflops, about 300 times faster.  And
<a href="https://en.wikichip.org/wiki/intel/hd_graphics_630">https://en.wikichip.org/wiki/intel/hd_graphics_630</a> says the later
Kaby Lake GPUs reach 134 single-precision GFlops with 24 EUs at 350
GHz, so maybe it’s plausible.
<a href="https://news.ycombinator.com/item?id=18146625">https://news.ycombinator.com/item?id=18146625</a> says the V100 also
costs US$10k, which is about 30× what my laptop costs, so the laptop
has 10× worse price-performance.</p>
<p>It supports OpenCL and GLSL.</p>
<p><a href="https://github.com/Themaister/GLFFT">https://github.com/Themaister/GLFFT</a> is an FFT implementation that
has been tested on another GPU in the family.
<a href="https://software.intel.com/en-us/intel-opencl">https://software.intel.com/en-us/intel-opencl</a> is OpenCL which I
think supports it.
<a href="https://en.wikichip.org/w/images/f/f4/Compute_Architecture_of_Intel_Processor_Graphics_Gen8.pdf">https://en.wikichip.org/w/images/f/f4/Compute_Architecture_of_Intel_Processor_Graphics_Gen8.pdf</a>
is a detailed description of the compute architecture.</p>
<p><a href="https://01.org/linuxgraphics/downloads/2018q1-intel-graphics-stack-recipe">https://01.org/linuxgraphics/downloads/2018q1-intel-graphics-stack-recipe</a>
calls Gen8 “Coffee Lake”.</p>
<p><a href="https://software.intel.com/en-us/articles/introduction-to-gen-assembly">https://software.intel.com/en-us/articles/introduction-to-gen-assembly</a>
is an introduction to its assembly language.</p>
<p>So an interesting thing here is that the GPU can do 51.2 billion
single-precision multiply-accumulates per second, or 51.2 billion
32-bit integer ops.  But the CPU is 1.6 GHz with four cores, each of
which supports the SSE4.2 instruction set extensions, which supports
SIMD operations on 128-bit vectors of, among other things, four 32-bit
floating-point or integer values.  Supposing that each core is capable
of running one such instruction each cycle, that’s 1.6 · 4 · 4 = 25.6
gigaflops of single-precision floating-point.  This is only half the
power of the GPU, but still, I think, substantially more than the
CPU’s non-SIMD capabilities.  There are even SIMD instructions that
allow you to use these 128-bit registers as 8 16-bit integers or 16
8-bit integers, though nothing for half-precision floats.</p>
<p>The problem with the SIMD i386/amd64 instructions — other than being
only having half the total computrons — is that there are a shitload
of them, and the instruction set is quite irregular, in large part due
to backward-combatibility concerns.</p><script src="../liabilities/addtoc.js"></script><div><h2>Topics</h2><ul><li><a href="../topics/programming.html">Programming</a> (286 notes)
</li><li><a href="../topics/performance.html">Performance</a> (149 notes)
</li><li><a href="../topics/gpgpu.html">GPGPU</a> (2 notes)
</li></ul></div></html>