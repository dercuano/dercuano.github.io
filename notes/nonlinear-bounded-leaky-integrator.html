<!DOCTYPE html>
<html><title>Nonlinear bounded leaky integrator ⁑ Dercuano</title><meta charset="utf-8"></meta><link href="../liabilities/style.css" rel="stylesheet"></link><meta content="width=device-width, initial-scale=1.0" name="viewport"></meta><h1>Nonlinear bounded leaky integrator</h1><div class="metadata">Kragen Javier Sitaker, 2019-09-11
(8 minutes)</div><p>An integrator or prefix sum is a linear low-pass filter with no
rolloff: 6 dB per octave all the way down to dc, where it diverges.
Sometimes it’s desirable to have a similar kind of filtering action
with BIBO stability, and there are a couple of standard linear ways to
do that.  A nonlinear approach just occurred to me, which is what this
note is about.</p>
<h2>The integrator and its standard variants</h2>
<p>The discrete integrator is the linear filter</p>
<blockquote>
<p><em>yᵢ</em> = <em>yᵢ</em>₋₁ + <em>xᵢ</em></p>
</blockquote>
<p>also known as the prefix sum, plus-scan, summed-area table, and other
terms; it’s the discrete analogue to the antiderivative operator.  It
amplifies frequencies by a linear gain factor proportional to their
wavelength, which means that it’s not BIBO stable: a bounded input
sequence with any dc bias will eventually produce an arbitrarily large
magnitude of output.  It’s marginally stable — if you stop stimulating
it with a dc bias, its output won’t keep growing.  Its impulse
response is the Heaviside step function.</p>
<p>It’s extremely inexpensive to compute.</p>
<p>If you’re doing this on a computer, sometimes this instability can be
bad.  In C, it can be undefined behavior.  In integer arithmetic, it
can overflow from positive to negative values or vice versa, which is
a problem under some circumstances.  In floating point, it results in
a gradual loss of precision which eventually becomes total, although,
for a signal with 16 bits of dynamic range being represented in a
64-bit IEEE-754 float, loss of precision doesn’t begin until you have
processed at least 2³⁷ samples.  In arbitrary-precision arithmetic,
which is generally not used for signal processing, it starts to use
more memory and become slower.</p>
<p>If you’re using the integrator as a model of some physical system,
such as a capacitor charging from an operational transconductance
amplifier, you have a potentially more serious problem: the system
almost certainly has some kind of physical bounds on its response, and
if your linear model has unbounded behavior, that means its
approximation of the physical system is going to be unboundedly awful
under some circumstances.</p>
<h3>The really long boxcar and its variants</h3>
<p>Consider composing the integrator above with the following sparse FIR
comb filter, producing a filter that is overall FIR and thus BIBO:</p>
<blockquote>
<p><em>yᵢ</em> = <em>xᵢ</em> - <em>xᵢ</em>₋₂₀₄₈₀</p>
</blockquote>
<p>This boxcar has the same output as the integrator on signals of less
than 20480 samples and on frequencies whose wavelength is much shorter
than 20480 samples, but for lower frequencies, its gain has an
asymptote of 20480, although the gain isn’t very well behaved; it has
sharp nulls at 2π = ω 20480 samples and its harmonics.</p>
<p>You could soften this a bit to something like</p>
<blockquote>
<p><em>yᵢ</em> = 3<em>xᵢ</em> - <em>xᵢ</em>₋₃₃₁₃₇ - <em>xᵢ</em>₋₂₀₄₈₀ - <em>xᵢ</em>₋₁₂₆₅₇</p>
</blockquote>
<p>so that you don’t have any really sharp nulls like that, just some
1.8-dB attenuations.</p>
<p>However, you still have striking time-domain artifacts in the form of
echoes: one at 33,137 samples, one at 20,480 samples, and one at
12,657 samples.</p>
<p>If you pass a signal through a filter with a Gaussian time-domain
response, followed by an integrator, you get a unstable filter with a
sigmoid impulse response, a sort of softened Heaviside step function.
You can approximate this closely with four integrators and three combs
like the comb above.  If you delay the output of this filter, scale it
down to unit magnitude, and subtract it from an integrator, you can
similarly tame the integrator and get it to be FIR and thus BIBO
stable, without much echo except at low frequencies and, I think,
without any sharp nulls; the impulse response of the combination is a
pulse with a sharp beginning, a flat top, and a slow sigmoid decline
to zero.  It costs one multiply, five adds, and four subtracts per
sample.</p>
<p>The stable approximation of an integrator provided by these LTI hacks
may be adequate for many purposes.</p>
<h3>Exponential leakage</h3>
<p>A simpler way to make the integrator BIBO stable without altering its
high-frequency response and LTI nature is to add a little bit of
exponential decay:</p>
<blockquote>
<p><em>yᵢ</em> = <em>kyᵢ</em>₋₁ + <em>xᵢ</em></p>
</blockquote>
<p>Here <em>k</em> is a decay factor between 0 and 1, say something like 0.99 or
0.999, analogous to a bleeder resistor across an accumulating
capacitor.  The impulse response of this filter is a pulse with a
sharp onset followed by an exponential decay back to zero with a time
constant <em>τ</em> = -1/(<em>fₛ</em> ln <em>k</em>).</p>
<p>This has no echoes or sharp nulls, but it’s not FIR like the boxcars.</p>
<h2>Nonlinear leakage through saturation</h2>
<p>Suppose we harshly clip our integrator output as if it were the output
of an ADC:</p>
<blockquote>
<p><em>yᵢ</em> = -<em>k</em> ∨ <em>yᵢ</em>₋₁ + <em>xᵢ</em> ∧ +<em>k</em></p>
</blockquote>
<p>(Here <em>a</em> ∨ <em>b</em> is <em>a</em> if <em>a</em> &gt; <em>b</em>, <em>b</em> otherwise, and <em>a</em> ∧ <em>b</em> =
-(-<em>a</em> ∨ -<em>b</em>).)</p>
<p>This guarantees that it’s BIBO stable because its output is bounded to
[-<em>k</em>, +<em>k</em>], no matter what the input is.  (This approach is commonly
used to limit integrator windup in PID controllers.)  It gives up
linearity, and in the process creates all kinds of potential for
interaction between frequencies.</p>
<p>An interesting thing about this approach is that if the integrator is
floating around near its limit when some high-frequency oscillation
starts, say with amplitude 0.1, that would force it beyond the limit,
the first quarter-cycle of that oscillation gets clipped; but
thereafter the whole oscillation proceeds without incident, having
added enough of a negative step function (a component at dc!) to make
room for the rest of its waveform below the saturation level.</p>
<p>Another interesting thing about it is that there are a lot of natural
phenomena that behave to some degree like this, including saturation
in transformers and ionic polarization in dielectrics (see <a href="../notes/coffee-humidity-sensing.html">Measuring the moisture content of coffee and other things with dielectric spectroscopy</a>); the optical Kerr effect can manifest such
effects at near-exahertz timescales.</p>
<h3>Softer saturation</h3>
<p>Suppose we’d like to get some of this effect, but with gentler
nonlinearity; we’d like to smoothly tilt the playing field for <em>x</em> so
that it can move <em>y</em> back toward zero a little more easily than it can
move <em>y</em> further away from zero.  This way, maybe we can get the BIBO
stability of the hard saturation thresholds, the same
no-cutoff-frequency low-pass filtering action of the pure integrator,
and minimal waveform distortion, except where these three conflict.</p>
<p>Maybe something like</p>
<blockquote>
<p><em>yᵢ</em> = (1 - <em>kxᵢ</em>²)<em>yᵢ</em>₋₁ + <em>xᵢ</em></p>
</blockquote>
<p>would do.  But I feel like this is maybe <em>too</em> nonlinear, since it
fails at BIBO.  Also requiring three multiplications per sample seems
like a lot, since the standard LTI exponentially-leaky integrator only
requires one.</p>
<p><em>xᵢyᵢ</em>₋₁ is negative when <em>xᵢ</em> is trying to decrease the magnitude of
<em>yᵢ</em>, and positive when it’s trying to increase them.  So an
alternative, simpler approach might be to use this factor to adjust
the gain on <em>xᵢ</em> smoothly:</p>
<blockquote>
<p><em>yᵢ</em> = <em>yᵢ</em>₋₁ + (1 - <em>kxᵢyᵢ</em>₋₁)<em>xᵢ</em></p>
</blockquote>
<p>This still requires three multiplications per sample.  The parameter
<em>k</em>, maybe in the range 0.0001 to 0.1, sets the maximum amplitude of
the output, which also depends on the frequency (relative to the
sampling rate) and the other existing frequencies.</p>
<p>This is imperfect — in particular, the gain goes negative
if <em>kxᵢyᵢ</em>₋₁ &gt; 1 — but it seems to be giving reasonable results on
some simple test signals.  It can produce extreme harmonic distortion
with undesirable values of <em>k</em>.</p>
<pre><code>def nlf(x, k=.025):
    y = x.copy()
    for i in range(1, len(y)):
        y[i] = y[i-1] + (1 - k*x[i]*y[i-1])*x[i]
    return y
</code></pre><script src="../liabilities/addtoc.js"></script><div><h2>Topics</h2><ul><li><a href="../topics/programming.html">Programming</a> (286 notes)
</li><li><a href="../topics/algorithms.html">Algorithms</a> (123 notes)
</li><li><a href="../topics/dsp.html">Digital signal processing (DSP)</a> (60 notes)
</li><li><a href="../topics/prefix-sums.html">Prefix sums</a> (18 notes)
</li></ul></div></html>