<!DOCTYPE html>
<html><title>Improving “science” in eSpeak's lexicon ⁑ Dercuano</title><meta charset="utf-8"></meta><link href="../liabilities/style.css" rel="stylesheet"></link><meta content="width=device-width, initial-scale=1.0" name="viewport"></meta><h1>Improving “science” in eSpeak's lexicon</h1><div class="metadata">Kragen Javier Sitaker, 2007 to 2009 (updated 2019-06-27)
(15 minutes)</div>
<p>So I've been playing around with speech synthesis software tonight.
<a href="http://espeak.sourceforge.net/">eSpeak</a> looks a lot nicer than
<a href="http://www.cstr.ed.ac.uk/projects/festival/">Festival</a>,
just in that it's much easier to adjust its speed,
correct its pronunciation,
and play with variations: 
whisper, different accents, pitch, word spacing, creaky voice.
I got to thinking,
what would a logical policy for updating its lexicon look like?
I thought the results I came up with were interesting.
Maybe some other people will be interested too.</p>
<h2>The problem</h2>
<p><a href="http://espeak.sourceforge.net">eSpeak</a>
gets “neuroscience” and “pseudoscience” wrong, 
pronouncing them with a <code>[[s,i@ns]]</code>
rather than a <code>[[s'aI@ns]]</code>.<br />
It also gets “omniscience” and “prescience” wrong, 
or at least pronounces them
rather differently than I would:</p>
<pre><code>$ ~/pkgs/espeak-1.37-source/src/speak -v en/en-r+f2 -s 250 -x "The 
    science of neuroscience is not a scientific or quasiscientific
    pseudoscience.  Conscientiously pursue omniscience and prescience."
 D@2 s'aI@ns Vv n'3:r-@s,i@ns I2z n,0t#@ saI@nt'IfIk _:_:O@ kw,eIzaIsi@nt'IfIk sj'u:d@s,i@ns
 k,0nsI2;'EnS@sli p3sj'u: '0mnIs,i@ns _:_:and pr'i:si@ns
</code></pre>
<p>I would pronounce the “science” in “omniscience” and “prescience” as
<code>[[S@ns]]</code> and put the accent on another syllable.</p>
<p>There’s a special rule for “scien” beginning a word, and for
“conscience”:</p>
<pre><code>en_list:conscience       k0nS@ns
en_rules:       _sc) ie (n        aI@
en_rules:?8     _sc) ie (n        aIa2
</code></pre>
<p>However, Jonathan Duddington has said
he wants to keep the eSpeak distribution small,
so he “wouldn’t want to include too many unusual or specialist words”.
(See <a href="http://sourceforge.net/forum/forum.php?thread_id=1700280&amp;forum_id=538920">http://sourceforge.net/forum/forum.php?thread_id=1700280&amp;forum_id=538920</a>
where he talks about why he doesn’t want to import the Festival lexicon.)
Already, <code>espeak-data/en_dict</code> is 80KB,
which is half the size of the <code>speak</code> binary.</p>
<h2>Replacement strategies</h2>
<p>There are several possible strategies
that a maintainer could adopt
in order to improve the coverage of their special-case word files
without letting them get large.
Suppose
that there is a scalar metric of “goodness”
that can be applied independently to each special case.
Here are three plausible strategies,
ordered from least to most stringent.</p>
<ul>
<li>C-: They could never remove items from the file,
  adding new items as long as they were better
  than the worst item in the file.
  This will probably cause 
  the average quality of the entries in the file
  to gradually decline,
  because many of the most important entries
  were probably added early on.
  It will eventually result in a very large file
  with very low average quality per entry,
  but very comprehensive coverage.</li>
<li>C+: They could keep the number of items in the file fixed,
  adding new items as long as they were better
  than the worst item in the file.
  This will cause the program
  to gradually work better,
  but each new version will introduce regressions ---
  words that the previous version pronounced correctly,
  but the new one does not.</li>
<li>A: They could never remove items,
  but add new items
  as long as they improved the median item quality of the file ---
  that is, as long as the new item
  improved the program’s performance
  more than most of the items in the file.
  This will gradually slow down and eventually stop
  the addition of new items,
  because that median quality will gradually increase.</li>
</ul>
<p>I am going to approximate “quality”
with “frequency”,
on the theory that mispronouncing a rare word
is always better than mispronouncing a common one.</p>
<p>Note the analogy
to Google’s famous hiring policy:
only hiring candidates who raised their average ability.</p>
<h2>Evaluating word frequencies</h2>
<p>Are these “science” words significant enough to include?
<code>en_list</code> only contains 2869 lines, maybe 2400 of which are words.
So maybe only the top 2400 or so exceptions
to the normal rules of pronunciation
are currently considered for inclusion.</p>
<p>Some time ago, I tabulated the frequencies of words 
in the British National Corpus 
and put the results online 
at <a href="http://canonical.org/~kragen/sw/wordlist">http://canonical.org/~kragen/sw/wordlist</a>.
It has 109557 lines,
ordered from the most common words
(“the”, “of”, and “and”, each occurring millions of times) 
to the least common
(with a cutoff of 5 occurrences,
because most of the words with fewer
were actually misspellings).</p>
<p>I selected 20 lines at random from <code>en_list</code>
with the following results:</p>
<pre><code>kragen@thrifty:~/pkgs/espeak-1.37-source/dictsource$ ~/bin/unsort &lt; en_list | head -20
this             %DIs          $nounf $strend $verbsf
barbeque         bA@b@kju:
con              k0n
?5 thu  TIR        // Thursday
_:      koUl@n
Ukraine         ju:kr'eIn
peculiar         pI2kju:lI3
unread           Vnr'Ed        $only
inference        Inf@r@ns
José            hoUs'eI
unsure           VnS'U@
survey                         $verb
ë       $accent
epistle          I2pIs@L
Munich          mju:nIk
scenic           si:nIk
synthesise       sInT@saIz
corps            kO@           $only
rajah            rA:dZA:
transports       transpo@t|s    $nounf
</code></pre>
<p>Where do these special cases appear
in the British National Corpus tabulation?
Here are some results,
edited for readability:</p>
<pre><code>kragen@thrifty:~/pkgs/espeak-1.37-source/dictsource$ grep -niE ' (this|barbeque
   |con|thu|ukraine|peculiar|unread|inference|José|unsure|survey|epistle|munich
   |scenic|synthesise|corps|rajah|transports)$' /home/kragen/devel/wordlist
22:463240 this
1178:7999 survey
5102:1441 peculiar
5831:1200 corps

7165:888 ukraine
8977:634 munich
9045:627 unsure
10552:494 inference

11134:455 con

15127:275 scenic
29899:82 epistle
31386:74 transports
34270:62 synthesise

37255:52 unread
73679:11 thu
74154:11 rajah
87737:8 barbeque
</code></pre>
<p>The 50th-percentile among the sample of 20
(of which two weren't words,
and a third wasn't found)
seems to be line 11 134
with the word “con”.
That is,
the exceptions in <code>en_list</code>
are mostly drawn
from the most frequently used
eleven thousand words in the language.
(Maybe words like “barbeque”, “rajah”, and “unread”
should be dropped.)</p>
<p>So under the policies “C+” and “C-”,
any word that is more common than “barbeque”,
at position 87737 in the British National Corpus tabulation,
(or maybe some word even a bit rarer than that)
should be added to the file.
(Under policy “C+”, 
some word would be removed to compensate,
raising the threshold.)
Under the policy “A”,
the threshold would be “con”, 
at position 11 134.</p>
<p>Unfortunately, José is missing.
I think I excluded accented characters
when I tabulated the frequencies initially.</p>
<p>Anyway, that gives us a way to compare
the “science” words:</p>
<pre><code>kragen@thrifty:~/pkgs/espeak-1.37-source/dictsource$ grep -n scien[tc]
    /home/kragen/devel/wordlist 
870:10597 science
1614:5922 scientific
2584:3547 scientists
3865:2088 sciences
3977:2005 scientist
5342:1355 conscience

13365:338 conscientious
16976:227 scientifically
25757:109 consciences
26015:107 conscientiously
27861:93 unscientific
37040:53 omniscient
44349:36 prescient
49031:29 neuroscience
49706:28 prescience
50457:27 scientificity
50587:27 omniscience
53155:24 scientism
62346:17 geoscience
66943:14 scientia
67285:14 neuroscientists
68176:14 conscientiousness
82060:9 geoscientists
84433:8 scientology
84434:8 scienter

86513:8 geosciences
90235:7 neurosciences
93073:7 biosciences
93074:7 bioscience
95039:6 scientifique
95591:6 pseudoscience
103190:5 presciently
103191:5 prescientific
</code></pre>
<p>Of these, only those more common than “conscience”
seem to deserve a place in <code>en_list</code>.
How does eSpeak do now?</p>
<pre><code>$ ~/pkgs/espeak-1.37-source/src/speak -v en/en-r+f2 -s 250 -x "Science is 
    scientific and done by scientists, who work in the sciences.  A 
    scientist with a conscience may be conscientious.  Those with 
    scientifically-minded consciences will conscientiously avoid 
    unscientific claims of omniscient beings or prescient prophets."
 s'aI@ns I2z saI@nt'IfIk _:_:and d'Vn baI s'aI@nt#Ists
 _:_:h,u: w'3:k I2nD@2 s'aI@nsI2z
 a2 s'aI@nt#Ist wI2D a2 k'0nS@ns m'eI bi: k,0nsI2;'EnS@s
 DoUz wI2D saI@nt'IfIkli m'aIndI2d k'0nS@nsI2z wIl k,0nsI2;'EnS@sli; a2v'OId
 VnsaI@nt'IfIk kl'eImz Vv '0mnIs,i@nt b'i:;INz _:_:O@ pr'i:si@nt pr'0fIts
</code></pre>
<p>It pronounces everything correctly
until it gets to "omniscient" and "prescient",
and maybe its pronunciations for those are correct,
but at least they’re not the pronunciations I would use.</p>
<p>Under policy “A”, 
those words are not common enough to add to <code>en_list</code>,
because they would lower 
the average frequency of words in <code>en_list</code>
unless you removed a less common word to compensate.</p>
<p>Under policies “C+” and “C-”,
not only “omniscient” and “prescient” qualify,
but so do 
“neuroscience”, “geoscience”, “neuroscientists”, and “geoscience”,
which eSpeak currently mispronounces.</p>
<p>(Including all the exceptions that as rare as “prescient”
might quadruple the size of <code>en_list</code>,
and perhaps <code>en_dict</code> as a result,
if arbitrary spellings were as common among rare words
as they are among common words.
Think of that as an upper bound.
Including all the exceptions as rare as “neuroscientists”
might multiply its size by seven.
This is the downside of policy “C-”,
but it does not happen with policy “C+”.
On the other hand,
under policy “C+”,
even “prescient” might not survive long after being added.)</p>
<h2>Recommendation</h2>
<p>There is a better solution
than adding a bunch of one-word special cases
to <code>en_list</code>.</p>
<p>Probably
in this case
the solution is to change the special case
for "conscience"
to a special case
for "conscien..."
and change the "scien..." rule
to a "...scien..." rule;
that covers all the words
except for "omniscien..."
and "prescien...".
Covering those two
takes only two more rules
in <code>en_rules</code>,
if it's considered worthwhile;
but "conscience" is ten times as common
as both of those together,
"con" three times as common,
but "barbeque" 18 times less common.</p>
<h2>Alternatives</h2>
<p>I think
there is a need for a larger <code>en_list</code> and <code>en_rules</code>
to be available,
even if they aren't part of the standard distribution.
eSpeak’s current footprint
for a single language
is about 160KB for the executable
and 80KB for the dictionary.
But it would be useful in many cases
even if its dictionary were 800KB
(as perhaps it would be with the Festival lexicon)
or 8MB.</p>
<p>And for a better user interface
for making changes to the dictionary,
and especially <code>en_rules</code>,
since currently it's hard to know
what words you're changing the pronunciation of
when you change <code>en_rules</code>,
and you have to master a phonological orthography system
to make any contribution at all.
And then there's no <code>git</code>-like infrastructure
for sharing your changes,
and even learning <code>git</code>
is a pretty big barrier to contributions.</p>
<p>If, instead,
you could twist a knob
to jog back to the last mispronounced word,
then hold down a button
and say its correct pronunciation,
the barrier to contributions would be much lower.
You would need
a reasonable phonological analysis system 
(like in a speech-to-text system)
to turn the spoken word into the string of phonemes.
Then, if you could share your accumulated corrections
with all other users of the software
with the push of a button,
the process of coming up with
the tens of thousands of special cases
would be a lot quicker.</p>
<h2>Update from 2019: eSpeak is super awesome now</h2>
<p>The above is about eSpeak 1.37 from perhaps 2008.  I currently have
eSpeak 1.48.03 from 2014 installed, and en_dict is now 116K instead of
80K.  The en/en-r voice used above doesn’t exist any more, but the
en-us voice is a fairly close equivalent:</p>
<pre><code>$ espeak -v en-us+f2 -s 250 -x "The science of neuroscience is not a scientific
     or quasiscientific pseudoscience.  Conscientiously pursue
     omniscience and prescience."
 D@2 s'aI@ns Vv n'U@r@s,aI@ns Iz n,0t#@ saI@nt'IfIk_:_: O@ kw,eIzaIsaI@nt'IfIk s'u:doUs,aI@ns
 k,0nsI2;'EnS@sli p3s'u: 0mn'IsI;@ns_:_: and pr'i:si@ns
</code></pre>
<p>It now pronounces “neuroscience” and “pseudoscience” correctly.  The
relevant part of <code>en_rules</code> is as follows:</p>
<pre><code>    sc) ie (nc     aI@
        ie (ntiC   aI@
   _sc) ie (n      aI@
?8 _sc) ie (n      aIa#
</code></pre>
<p>I think that means that now the “ie” in any instance of “scienc” will
be pronounced as “aI@”, regardless of whether it’s at the beginning of
the word, which is what the “_” in the last two entries means, as
explained in docs/dictionary.html in the eSpeak source code.</p>
<p>My other example now renders as follows:</p>
<pre><code>$ espeak -v en-us+f2 -s 250 -x "Science is 
        scientific and done by scientists, who work in the sciences.  A 
        scientist with a conscience may be conscientious.  Those with 
        scientifically-minded consciences will conscientiously avoid 
        unscientific claims of omniscient beings or prescient prophets."

s'aI@ns Iz saI@nt'IfIk_:_: and d'Vn baI s'aI@ntIsts
 h,u: w'3:k InD@2 s'aI@nsI#z
 a# s'aI@ntIst wID a# k'0nS@ns m'eI bi: k,0nsI2;'EnS@s
 DoUz wID saI@nt'IfIklim'aIndI#d k'0nS@nsI#z wI2l k,0nsI2;'EnS@sli; a#v'OId
</code></pre>
<p>(line break inserted)</p>
<pre><code>VnsaI@nt'IfIk kl'eImz Vv 0mn'IS@nt b'i:;I2Nz_:_: O@ pr'i:si@nt pr'0fI2ts
</code></pre>
<p>This is different in several details from the above, but overall it
doesn’t seem to be worse in any way.  Also, eSpeak now has an <code>--ipa</code>
option, which produces the following output instead:</p>
<blockquote>
<p>sˈaɪəns ɪz saɪəntˈɪfɪk ænd dˈʌn baɪ sˈaɪəntɪsts<br />
 hˌuː wˈɜːk ɪnðə sˈaɪənsᵻz<br />
 ɐ sˈaɪəntɪst wɪð ɐ kˈɑːnʃəns mˈeɪ biː kˌɑːnsɪˈɛnʃəs<br />
 ðoʊz wɪð saɪəntˈɪfɪklimˈaɪndᵻd kˈɑːnʃənsᵻz wɪl kˌɑːnsɪˈɛnʃəsli ɐvˈɔɪd ʌnsaɪəntˈɪfɪk klˈeɪmz ʌv ɑːmnˈɪʃənt bˈiːɪŋz ɔːɹ pɹˈiːsiənt pɹˈɑːfɪts  </p>
</blockquote>
<p>To me, this is dramatically more readable, but it is omitting some
details that are important to at least eSpeak’s pronunciation; for
example, the <code>_:_:</code> pause above doesn’t seem to appear, nor does the
distinction between I (stressed) and I2 (unstressed, but not reduced
like the undocumented I#).  You can use it to translate from eSpeak’s
internal format to IPA by using <code>[[]]</code>:</p>
<pre><code>$ espeak -v en-us+f2 -s 250 --ipa "[[h,u: w'3:k InD@2 s'aInsI#z]]"
 hˌuː wˈɜːk ɪnðə sˈaɪnsᵻz
</code></pre>
<p>This makes it easy to compare the old and new pronunciations
simultaneously by ear and by reading the IPA transcription, which
reveals a few different improvements:</p>
<pre><code>$ espeak -v en-us+f2 -s 250 --ipa "[[D@2 s'aI@ns Vv n'3:r-@s,i@ns I2z n,0t#@ saI@nt'IfIk _:_:
O@ kw,eIzaIsi@nt'IfIk sj'u:d@s,i@ns]].
[[k,0nsI2;'EnS@sli p3sj'u: '0mnIs,i@ns _:_:and pr'i:si@ns]].
The science of neuroscience is not a scientific or quasiscientific pseudoscience.
Conscientiously pursue omniscience and prescience."

ðə sˈaɪəns ʌv nˈɜːɹəsˌiəns ɪz nˌɑːɾə saɪəntˈɪfɪk  ɔːɹ kwˌeɪzaɪsiəntˈɪfɪk sjˈuːdəsˌiəns
 kˌɑːnsɪˈɛnʃəsli pɚsjˈuː ˈɑːmnɪsˌiəns ænd pɹˈiːsiəns
 ðə sˈaɪəns ʌv nˈʊɹɹəsˌaɪəns ɪz nˌɑːɾə saɪəntˈɪfɪk ɔːɹ kwˌeɪzaɪsaɪəntˈɪfɪk sˈuːdoʊsˌaɪəns
 kˌɑːnsɪˈɛnʃəsli pɚsˈuː ɑːmnˈɪsɪəns ænd pɹˈiːsiəns
</code></pre>
<p>This also means you can use it with <code>-q</code> as a fairly reliable
converter from standard English orthography to IPA:</p>
<blockquote>
<p>ðɪs ˈɑːlsoʊ mˈiːnz juː kæn jˈuːz ɪt wɪðkjˈuː æz ɐ ɹˈæpɪd ænd fˈɛɹli ɹɪlˈaɪəbəl kənvˈɜːɾɚ fɹʌm stˈændɚd ˈɪŋɡlɪʃ ɔːɹθˈɑːɡɹəfi tʊ ˌaɪpˌiːˈeɪ</p>
</blockquote>
<p>It’s a little slow for use in this mode; converting the first 83955
words of the KJV took 1'57" on my laptop, which is only 718 words per
second, about three times faster than speech.  But this speed is
sufficient to solve many problems with.  The particular problem that
made me update this note tonight is that of finding sets of minimal
pairs of English words for ESL learners to learn to distinguish the
phonemes in, the hard part of which for a computer is finding out what
the pronunciations of the English words are; the following command
lines generated a decent pronouncing dictionary in just over 5
minutes:</p>
<pre><code>$ espeak -v en-us+f2 --ipa -q &lt; /usr/share/dict/words &gt; words-ipa-2
$ paste /usr/share/dict/words words-ipa-2 &gt; pronunciation-dictionary
</code></pre><script src="../liabilities/addtoc.js"></script><div><h2>Topics</h2><ul><li><a href="../topics/hci.html">Human–computer interaction</a> (76 notes)
</li><li><a href="../topics/small-is-beautiful.html">Small is beautiful</a> (40 notes)
</li><li><a href="../topics/audio.html">Audio</a> (40 notes)
</li><li><a href="../topics/strategy.html">Strategy</a> (10 notes)
</li><li><a href="../topics/nlp.html">Natural-language processing</a> (6 notes)
</li><li><a href="../topics/speech-synthesis.html">Speech synthesis</a> (3 notes)
</li><li><a href="../topics/phonetics.html">Phonetics</a> (3 notes)
</li><li><a href="../topics/espeak.html">Espeak</a> (2 notes)
</li></ul></div></html>