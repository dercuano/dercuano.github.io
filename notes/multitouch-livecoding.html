<!DOCTYPE html>
<html><title>Multitouch livecoding ⁑ Dercuano</title><meta charset="utf-8"></meta><link href="../liabilities/style.css" rel="stylesheet"></link><meta content="width=device-width, initial-scale=1.0" name="viewport"></meta><h1>Multitouch livecoding</h1><div class="metadata">Kragen Javier Sitaker, 2018-06-17
(1 minute)</div><p>I thought it would be interesting to explore multitouch interfaces for
livecoding music.  Here are some ideas:</p>
<ul>
<li>On a cellphone, you can expand your working area by using the phone
  accelerometers (and gyros, if available) to rotate the phone to move
  around a larger virtual space.</li>
<li>Quasimodal interface elements pop up during a touch and then permit
  continuous adjustment in one or more dimensions with one or more
  touches — the same or different touches.</li>
<li>Waveform and spectrum displays at different scales can elucidate
  what is happening in a single node.</li>
<li>Individually reified signal inputs might offer a quasimodal action
  to overwrite them with some existing signal.</li>
</ul><script src="../liabilities/addtoc.js"></script><div><h2>Topics</h2><ul><li><a href="../topics/programming.html">Programming</a> (286 notes)
</li><li><a href="../topics/hci.html">Human–computer interaction</a> (76 notes)
</li><li><a href="../topics/audio.html">Audio</a> (40 notes)
</li><li><a href="../topics/music.html">Music</a> (18 notes)
</li><li><a href="../topics/multitouch.html">Multitouch</a> (12 notes)
</li></ul></div></html>